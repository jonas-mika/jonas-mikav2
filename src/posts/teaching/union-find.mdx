---
title: Union Find
description:
course: Algorithms & Data Structures
tags: []
published: 2022-01-31
lastEdited: 2022-01-31
---

## Introduction

---

The first week of ADS deals with the famous union-find data structure (also:
_disjoint-set data structure_). It is used to store information about the
connectivity of elements (usually integer-encoded from $0$ to $N$).

### Algorithmic Problem Setting

---

Given a sequence of pairs of integers, where each integer represents an object
of some type and we are to interpret the pair $(p,q)$ as meaning $p$ is
connected to $q$.

We assume connectivity to be an equivalence relation, such that:

- **Reflexive** (to oneself): $p$ is always connected to $p$
- **Symmetric**: If $p$ is connected to $q$, then $q$ is connected to $p$
- **Transitive**: If $p$ is connected to $q$ and $q$ is connected to $r$, the
  $p$ is connected to $r$

Such an equivalence relations partitions the objects into equivalence classes
(or sets). In this case, two objects are in the same equivalence class if and
only if they are connected (not necessarily directly). We encounter equivalence
relation partitions frequently as data scientists and mathematics.

- **Mathematical View**: A sequence of equivalence relations as above maps to
  the mathematical definition of a set, which describes a collection of (unique)
  elements.

- **Network Analysis View**: We can map equivalence relations into the setting
  of network analysis, by mapping each element as a node in an undirected graph,
  and say that two elements within this graph are related, if there is exists a
  path between them. Following this idea, the connected components of the
  emerging graphs, are the equivalence classes (partitions).

## Applications

---

The `UnionFind` data structure is a basic data structure that is not only used
to solve disjoint sets problems (such as
[`itu.disjoint_sets`](https://itu.kattis.com/sessions/peum2r/problems/itu.disjointsets)),
but also commonly used within more complex algorithms, such as
[Kruskal's](https://en.wikipedia.org/wiki/Kruskal%27s_algorithm) algorithm to
find the minimum spanning tree (MST) to check whether adding the next
lowest-weigh edge creates a cycle.

## Implementation

---

The union-find data structure is initialised for $N$ elements and should
implement methods that allow to merge (union) the sets in which some element $p$
and some element $q$ are part of (`union(p, q)`), as well as checking whether
two elements $p$ and $q$ are connected to each other, ie. are in the same set
(`connected(p, q)`). More functionality can be implemented to support more
complex querying for this data structure. The (Python-like) pseudo-code for the
union-find API looks like this:

```python
class UF:
  def (__init__, n): pass # initialise UF with n elements

  def find(self, p): pass # class identifier for component p

  def union(self, p, q): pass # add connection between p and q

  def connected(self, p, q): pass # return True if there is a connection between p and q

  def __len__(self): pass # return the number of components (disjoint sets)
```

Let's now look at different ideas of _how to implement_ this class interface,
and - more importantly - _how to do it fast_.

### Quick-Find UF

---

Quick-find implements a very simple idea to solve the problem: **Let's maintain
an identifier of the component each element belongs to**. It becomes obvious,
how this leads to a very fast ($O(1) \rightarrow \text{Constant time}$; _you
will learn more about this in week 3_) implementation of the `find(p)` method,
since it is a single array access of the array storing all identifiers.
Following this, we can easily answer the question of whether two components are
connected (implementing `connnected(p, q)`) by finding the identifiers of both
elements and answer that the elements are connected if and only if their
identifiers are the same. This operation again runs in constant time (as it
involves 2 array accesses and a single boolean comparison).

The major flaw of the quick-find UF is the implementation of `union(p, q`
method. In order to union the two sets $p$ and $q$ belong to respectively, we
need to iterate over the entire array of identifiers and change all identifiers
of the one class to the identifiers of the other class. It is clear, that this
operation is linear in the number of elements $n$ stored in the UF data
structure and runs in $O(n)$. Linear time is a real-bottle neck for most use
cases for the UF data structure, where many calls to `union(p, q)` happen.
Imagine, as an example, to union a set of $n$ disjoint sets until all elements
are connected. This requires $n-1$ calls to union and thus the running time is
$n-1
\cdot n$, which is quadratic time $O(n^2)$ in big-O notation (_again, you
learn about the details of the analysis of running times of algorithms later_).

For a Python implementation of the quick-find UF data structure visit:

- [My GitHub](https://github.com/mikasenghaas/data-structures-and-algorithms/blob/master/fundamentals/union_find/quick_find.py)
- [itu.algs4.fundamentals.uf](https://github.com/itu-algorithms/itu.algs4/blob/master/itu/algs4/fundamentals/uf.py)

### Quick-Union UF

---

The name hints at it already: The quick-union UF implementation aims at
improving the running time of the `union(p, q)` operation, which ran in horrible
linear time in the quick-find idea.

It does so by introducing the idea of a parent-link array. A parent-link array
is a simple data structure for representing
[trees](<https://en.wikipedia.org/wiki/Tree_(data_structure)>) in a
computationally light fashion. It maintains an array in the length of the
elements (nodes) in the tree and for each node stores the identifier of its
parent node. The root node - logically - points to itself.

Using this data structure, to represent the disjoint sets, we need to adjust the
implementation of `find`. Now the array does not store the direct set
identifiers anymore, but simply the parent node. Two nodes - however - are said
to be connected (in the same set) if and only if their root node is the same.
Thus, in order to find the set identifier we follow the parent-link structure
until we reach the node. If two of such upwards traversals lead to the same root
node, we say that the nodes are connected and return True on a call to
`connected(p, q)`.

Let's look at the more interesting implementation of `union(p, q)`. After all,
cutting down the running time of this method was our goal in a first place. Once
we found the set identifiers of both the two elements to connect (which are the
roots found from a call to `find(p)` and `find(q)`, we choose one of the roots
at random to change its identifier from pointing to itself (since it was a root)
to the other root. Through a single array access, we have thus merged all
elements in the two disjoint sets $p$ and $q$ belonged to.

What is the running time of this? If you read carefully, you have noticed, that
both the `connected` and `union` method depend on how fast we can find the root
of the two elements queried. Thus, the real question is, how fast a call to
`find(p)` is. It turns out that the average running is logarithmic, ie. we
connected nodes in a way that we get fairly balanced trees, which are not larger
than depth $log(n)$ (when saying log, we usually mean the logarithm to the base
2 $log_2$). However, randomly point either root node to the other in a call to
`union(p, q)` can lead to highly unbalanced trees. Consider ie. the following
sequence of union operations initialised for 5 ($\{i | 0 \le i \lt 5 \}$)
elements, with the invariant that we also update the root of p to the root of q.

```text
Union 0-1
Union 1-2
Union 2-3
Union 3-4
```

which creates the following tree (under the assumption of connecting
$p \rightarrow q$)

```text
        4
       /
      3
     /
    2
   /
  1
 /
0
```

In this example traversing the tree is actually linear in the number of nodes,
ie. $O(n)$. This means, that the worst case running time of both `connected` and
`union` is linear. Is this really better than the guaranteed running times
quick-find had for us? Let's look at how we can solve this.

For a Python implementation of the quick-union UF data structure visit:

- [My GitHub](https://github.com/mikasenghaas/data-structures-and-algorithms/blob/master/fundamentals/union_find/quick_union.py)
- [itu.algs4.fundamentals.uf](https://github.com/itu-algorithms/itu.algs4/blob/master/itu/algs4/fundamentals/uf.py)

### Weighted-Quick-Union UF

---

Fortunately, there is an easy modification to quick-union that allows us to
guarantee that the bad case never happens and - even better - guarantees to
build balances tree with logarithmic time $O(log\ n)$ for a call to `find`. The
idea is simple: Rather than arbitrarily connecting either root to the other root
(as in quick-union) we keep track of the _size_ of each tree and always connect
the smaller tree to the larger. This change requires slightly more code and
another array to hold the node counts but it leads to substantial improvements
in efficiency. We refer to this algorithm as the **weighted quick-union**
algorithm. It is a classical example of trading memory (space complexity) for
faster running times (time complexity), which is a common theme in designing
algorithms.

For a Python implementation of the weighted-quick-union UF data structure visit:

- [My GitHub](https://github.com/mikasenghaas/data-structures-and-algorithms/blob/master/fundamentals/union_find/weighted_quick_union.py)
- [itu.algs4.fundamentals.uf](https://github.com/itu-algorithms/itu.algs4/blob/master/itu/algs4/fundamentals/uf.py)

## Exercise Solutions

---

### 1.1.14: Algorithm Design

---

The largest integer not larger than the base-2 logarithm of any integer N can be
algorithmically found by halving the initial number $n$ iteratively until the
number is smaller than 1. We count the number of loops through a variable and
return this counts.

That is, because the base two logarithm of any number is the solution to the
mathematical expression $2^x = N$, meaning that the amount of times we can
multiply 2 while $2 \cdot ... \cdot 2 <= N$ is satisfied is the solution to the
problem.

```python
def lg(n):
  c = 0
  while n > 1:
    n //= 2
    c+= 1
  return c
```

### 1.5.1: Quick-Find

---

Show `id` array on a quick-find for the following sequence:

```text
  9-0 3-4 5-8 7-2 2-1 5-7 0-3 4-2
```

The output was created from the official `itu.algs4.fundamentals.uf.QuickFindUF`
implementation. Each call to union iterates over the entire array of singletons
and updates all singletons having the same set identifier as p to q's set
identifier for a call `union(p,q)`.

```text
            0  1  2  3  4  5  6  7  8  9
            ----------------------------
Initial  : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Union 9-0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 0]
Union 3-4: [0, 1, 2, 4, 4, 5, 6, 7, 8, 0]
Union 5-8: [0, 1, 2, 4, 4, 8, 6, 7, 8, 0]
Union 7-2: [0, 1, 2, 4, 4, 8, 6, 2, 8, 0]
Union 2-1: [0, 1, 1, 4, 4, 8, 6, 1, 8, 0]
Union 5-7: [0, 1, 1, 4, 4, 1, 6, 1, 1, 0]
Union 0-3: [4, 1, 1, 4, 4, 1, 6, 1, 1, 4]
Union 4-2: [1, 1, 1, 1, 1, 1, 6, 1, 1, 1]
```

### 1.5.2: Quick-Union

---

Show `parent` array on a quick-find for the following sequence:

```text
  9-0 3-4 5-8 7-2 2-1 5-7 0-3 4-2
```

The output was created from the official `itu.algs4.fundamentals.uf.QuickFindUF`
implementation.

```text
            0  1  2  3  4  5  6  7  8  9
            ----------------------------
Initial  : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Union 9-0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 0]
Union 3-4: [0, 1, 2, 4, 4, 5, 6, 7, 8, 0]
Union 5-8: [0, 1, 2, 4, 4, 8, 6, 7, 8, 0]
Union 7-2: [0, 1, 2, 4, 4, 8, 6, 2, 8, 0]
Union 2-1: [0, 1, 1, 4, 4, 8, 6, 2, 8, 0]
Union 5-7: [0, 1, 1, 4, 4, 2, 6, 2, 8, 0]
Union 0-3: [4, 1, 1, 4, 4, 2, 6, 2, 8, 0]
Union 4-2: [4, 1, 1, 4, 1, 2, 6, 2, 8, 0]
```

### 1.5.3: Weighted Quick-Union

---

Show `parent` array on a quick-find for the following sequence:

```text
  9-0 3-4 5-8 7-2 2-1 5-7 0-3 4-2
```

The output was created from the official `itu.algs4.fundamentals.uf.UF`
implementation.

```text
            0  1  2  3  4  5  6  7  8  9
            ----------------------------
Initial  : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Union 9-0: [9, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Union 3-4: [9, 1, 2, 3, 3, 5, 6, 7, 8, 9]
Union 5-8: [9, 1, 2, 3, 3, 5, 6, 7, 5, 9]
Union 7-2: [9, 1, 7, 3, 3, 5, 6, 7, 5, 9]
Union 2-1: [9, 7, 7, 3, 3, 5, 6, 7, 5, 9]
Union 5-7: [9, 7, 7, 3, 3, 5, 6, 5, 5, 9]
Union 0-3: [9, 7, 7, 9, 3, 5, 6, 5, 5, 9]
Union 4-2: [9, 7, 5, 9, 9, 9, 6, 5, 5, 9]
```

### 1.5.8: Incorrect `union()`

---

The following problem occurs with the given implementation of `union()` in a
quick-find implementation:

The boolean statement in each iteration of the for-loop is dynamically querying,
if the identifier of the i-th element is equivalent to the identifier of the
p-th element. This can cause trouble, if several elements need to be updated.
After the first element is being updated, the boolean expression will never
evaluated true anymore, disallowing unioning all elements in a set.

Consider the following example, where a union-operations breaks:

```text
Initial   : [0 1 2]
Union 2-0 : [0 1 0] (works)
Union 0-1 : [1 1 0] (fails)
```

The last union, should have resulted in an `id` array, in which all elements are
the same, leading to a single set. However, because after the first iteration
over the elements, the id of $p$ (`id[0]=1`) has changed, which leads to every
following elements that is `1` to be overwritten with a `1` and the all zeros,
that should be replaced with a one, to not be changed.

The union operation therefore completely breaks. For the code to run smoothly, a
reference to the id of $p$ is needed. Another reference to the id of $q$ can be
saved for fewer array accesses in the loop. The following code runs correctly:

```python
def union(self, p, q):
  if self.connected(p, q):
    return

  id_p = self._find(p)
  id_q = self._find(q)

  for i in range(self._n):
    if self._find(i) == id_p:
      self._id[i] = id_q

  self._count -= 1
```

### 1.5.9: Weighted Quick-Union Find

---

The below tree can never occur for a weighted quick union find implementation,
since the tree is 4 deep, which is larger than the guaranteed maximal tree depth
created by weighted quick union find: $5 \gt floor(log_2(10))=3$.

```text
i     0 1 2 3 4 5 6 7 8 9
id[i] 1 1 3 1 5 6 1 3 4 5
```

```text
      1
    / | \
   0  3  6
     / \   \
    2   7   5
           / \
          9   4
               \
                8
```
