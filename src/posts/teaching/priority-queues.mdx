---
title: Priority Queues
description:
course: Algorithms & Data Structures
tags: []
published: 02-28-2022
lastEdited: 02-05-2023
---

This week we are dealing with yet another fundamental data structure - the
**priority queue**. It is a natural extension of the `Queue` and `Stack` data
structure that we have already encountered, but should support a fast
implementation of the `max()` or `deleteMax()` methods, that - as the name
suggest - should retrieve the largest element stored in the priority queue.

## Motivation

---

Many applications require that we process items having keys in order, but not
necessarily in full sorted order and not necessarily all at once. Often, we
collect a set of items, then process the one with the largest key, and so forth.
This effect is typically achieved by assigning a priority to events associated
to applications, then always choosing to process next the highest-priority
events.

A data type that encompasses this behaviour are the so called **Max Priority
Queues** (or: _MaxPQ_, where the highest key has priority) or **Min Priority
Queues** (or: _MinPQ_, where the smallest key has highest priority).

## API

---

The API of the priority queues looks similar to those of regular queues (FIFO)
or stacks (LIFO), but is much more challenging to implement, since the operation
`remove_max()`, which is the signature of MaxPQ, requires to find the max,
return it and rearranges the indices in the array.

## Heap Data Structure

---

We can implement Priority Queues in the same way using either _linked lists_ or
_dynamic arrays_ and we will get fine performance on small inputs. On bigger
inputs, however, either the `remove_max()` operation (in case of the unordered
array) or the `insert()` operation takes linear time.

A new data structure, the so-called **Heap** promises to have logarithmic time
complexity on both operations and is therefore the best data structure for
implementing priority queues.

The _binary heap_ is a data structure that can efficiently support the basic
priority queue-operations. _Binary heaps_ are best represented as graphs - more
precisely trees (an undirected _graph that for each vertex has at most two
out-edges and at most (except for root) one in-edge)_. The special term of
_binary heaps,_ that modifies the classic binary tree data structure is the
.following property:

> A binary tree is **heap-ordered** if the element in each vertex is larger than
> or equal to the keys in that node's two children (if any).

From this general property about heap-order, we can derive more characteristics
of the heap data structure:

- Equivalently, the key in each node of a heap-ordered binary tree is smaller
  than or equal to the key in that node's parent (if any).

- Moving up from any node, we get a non-decreasing sequence.

- Moving down from any node, we get a non-increasing sequence.

- Therefore, the largest element in a heap-ordered binary tree is found at the
  root.

## Representing Heaps

---

We could implement binary heap data structures using _linked lists._ This,
however, would require to keep track of three links for each node, in order to
be able to arbitrarily travel up and down the heap: A link to the parent, and
one link to each of the two children.

Since this is rather memory inefficient, and because of the rather simple
properties of binary heaps, it is better to represent binary heaps in _dynamic
arrays_, where the root of the heap (largest element) is at index 1 (this is
necessary to allow easy arithmetics to access parents and children for each
node). The roots children are at indexes 2 and 3, and their children at indexes
4, 5 and 6, 7. Such an implementation allows to access children and parent of an
arbitrary element in the heap using simple arithmetic operations:

- _Accessing Children: $2k$, $2k+1$_

- _Accessing Parent (for node at index $k$): $floor(k/2)$_

### Reheapify

---

We know that binary heaps are easily represented by _dynamic arrays_, where the
highest priority item is at index $1$ and the children in heap order are
recursively found at the positions $2k$ and $2k+1$ (where $k$ is the index of
the node in question).

However, for the data structure to work as expected (and return the current
highest priority item through a simple array access at index $1$, we have to
maintain heap order (_also: fulfil heap condition_) throughout the whole process
of insertions and removals from the priority queue).

There are two options that potentially violate the heap order, that we need to
consider in order to prevent possible violations of the heap condition

1. **Bottom-Up Reheapify (Swim)**

   If the heap order gets violated in a way that a node's key becomes larger
   than that node's parent's key, we restore heap order using the `swim()`
   operation. This means, that we successively exchange the node with its parent
   until heap order is restored.

   We use this operation whenever we insert an element into the priority queue:

   `insert()` - We add the new element at the end of the array, increment the
   sizer of the heap, and then swim up through the heap with that element to
   restore heap order

   ```python
   def swim(self, k):
      # only swim up if not already root and if parent is smaller
      while k > 1 and self._less(self.pq, k//2, k):
        self._exchange(self.pq, k//2, k)  # _exchange with parent
        k //= 2  # reset k to see if another _swim needs to be performed
   ```

2. **Top-Down Reheapify (Sink)**

   If the heap order gets violated in a way that node's key becomes smaller than
   one or both of that node's children, then we restore heap order using the
   `sink()` operation. This means, that we successively exchange the node with
   the larger of its children until both children of the node are smaller than
   the node and we therefore have heap order.

   We use this operation whenever we remove the highest priority item from the
   priority queue:

   `remove_max()` - We take the highest priority item off the top (root of the
   heap, element at index 1), put the item from the end of the heap at the top,
   decrement the size of the heap, and then sink down through the heap with that
   element to restore heap order.

   ```python
   def sink(self, k):
    while (2*k <= self.n):  # can only _sink if not leaf ( 2*index at root will also be > n )
        j = 2*k  # child
        # if left child smaller than right, move j to right
        if j < self.n and self._less(self.pq, j, j+1):
            j += 1
        # don't sink if k (current node) is larger than its two children
        if self.less(self.pq, j, k):
            break
        self.exchange(self.pq, k, j)  # otherwise exchange
        k = j  # reset k to potentially sink further
   ```

## Exercise Solutions

---

### 2.4.1 Priority Queues

---

The below sequence of insertions of letters into a `MaxPQ` will produce the
following the following sequence when `remove_max` is called for for the
asterics:

```text
P R I O * R * * I * T * Y * * * Q U E * * * U * E
```

The returned `max` elements from the PQ will produce the following sequence:

```text
R R P O T Y I I U Q E U
```

The array that underlies the PQ at after every call to `remove_max` looks as
follows:

```text
Removing Max: R: [None, 'R', 'P', 'I', 'O']
Removing Max: R: [None, 'R', 'P', 'I', 'O']
Removing Max: P: [None, 'P', 'O', 'I']
Removing Max: O: [None, 'O', 'I', 'I']
Removing Max: T: [None, 'T', 'I', 'I']
Removing Max: Y: [None, 'Y', 'I', 'I']
Removing Max: I: [None, 'I', 'I']
Removing Max: I: [None, 'I']
Removing Max: U: [None, 'U', 'Q', 'E']
Removing Max: Q: [None, 'Q', 'E']
Removing Max: E: [None, 'E']
Removing Max: U: [None, 'U']
```

### 2.4.4 Heap-Order

---

An array is heap-order if the following two relations hold for every $k$ in the
array.

```text
arr[k] >= array[2k]
arr[k] >= array[2k+1]
```

Since in a strictly decreasing array, arr[k] >= arr[k+1], the above inequalities
also hold, and we can conclude that a strictly decreasing array is also in heap
order.

### 2.4.5 Inserting into MaxPQ

---

Inserting the keys E A S Y Q U E S T I O N into an initially empty `MaxPQ`
produces the following heap structure, represented as an array, after each
insert. Note, that we can draw the tree, by viewing the element at index $k$ as
the parent to the children at the indices $2k$ and $2k+1$, starting from $k=1$.

```text
After inserting E: [None, 'E']
After inserting A: [None, 'E', 'A']
After inserting S: [None, 'S', 'A', 'E']
After inserting Y: [None, 'Y', 'S', 'E', 'A']
After inserting Q: [None, 'Y', 'S', 'E', 'A', 'Q']
After inserting U: [None, 'Y', 'S', 'U', 'A', 'Q', 'E']
After inserting E: [None, 'Y', 'S', 'U', 'A', 'Q', 'E', 'E']
After inserting S: [None, 'Y', 'S', 'U', 'S', 'Q', 'E', 'E', 'A']
After inserting T: [None, 'Y', 'T', 'U', 'S', 'Q', 'E', 'E', 'A', 'S']
After inserting I: [None, 'Y', 'T', 'U', 'S', 'Q', 'E', 'E', 'A', 'S', 'I']
After inserting O: [None, 'Y', 'T', 'U', 'S', 'Q', 'E', 'E', 'A', 'S', 'I', 'O']
After inserting N: [None, 'Y', 'T', 'U', 'S', 'Q', 'N', 'E', 'A', 'S', 'I', 'O', 'E']
```

### 2.4.7 Heap-Order

---

In a max-oriented priority queue the largest element is always at the root of
the heap (or at index 1 at the underlying dynamic array data structure).
Naturally, the second largest element is one of the two children of the root, so
an element either at index 2 or 3.

It follows, that the third third largest element can be in the following
positions:

```text
Third largest element: 2,3,4,5,6,7
Fourth largest element: 2,3,4,5,6,7,8,9,10,11,12,13,14,15
```

### 2.4.9 Heap-Order

---

For the keys `A B C D E`

```text
    E         E          E          E         E         E          E          E
  D   C     D   C      C   D      C   D     D   A     D   A      D   B      D   B
B   A     A   B      B   A      A   B     B   C     C   B      A   C      C   A
```

For the keys `A A A B B` the following heaps can be constructed:

```text
    B           B
  B   A       A   B
A   A       A   A
```

### 2.4.11/12 Different PQ Implementations

---

The priority queue as implemented with a heap was designed with the idea to be
most efficient for generic applications that require to remove the maximum or
minimum key stored in the collection of elements. Thus, it's running time is
logarithmic for both insertion of keys and logarithmic for removing the maximum/
minimum element in the PQ. However, when we can make further assumptions about
the sequence of operations we are doing on our data structures, simpler
implementations might lead to improved performance.

The following table shows the running time on the two critical operations on the
PQ data structure for different underlying data structures.

```text
                  Insertion     Remove Max
Heap PQ           O(lg N)       O(lg N)
Ordered Array     O(N)          O(1)
Unordered Array   O(1)          O(N)
```

Specifically, if the number of calls to `insert()` is incredibly high and
dominates just a few calls to `remove_max()`, then a data structure that is
faster on insertions, but slower on removing the max element is beneficial. A
simple unordered array, with constant insertion (or amortised constant in the
case of the dynamic array), but linear time for finding the maximum element
would be best to use.

In turn, if the number of calls to `remove_max()` dominates the number of
insertions, then the time-critical operation is removing the maximum element and
the data structure that performs best on this operation should be used. Since
the ordered array has constant running time for removing the maximum element, an
ordered array should be used for such a task.

### 2.4.21 Heap PQ for Stack and Queue

---

The `Stack` and `Queue` are both fundamental data structures that restrict the
way we can access elements stored in the collection type.

The stack implements `push` and `pop` operation, where `pop()` should return and
delete the element from the collection that was _most recently added_.

Reversely, a queue implements a `enqueue` and `dequeue` operation, where
`dequeing` and item should return and remove the _least recently added_ item.

We can use the regular `MaxPQ` or `MinPQ` API, that is able to remove the
maximum key to replicate this behavior, by making a custom class `PQItem` that
alongside the actual values also stores an ID representing the order of
insertion of the keys. Instances of the `PQItem` are compared not by their
actual stored key, but by their order of insertion ID, making the least recently
added insertion ID the root of a `MaxPQ`, such that a call to `remove_max`
removes the most recently added items.

Similarly, we can use a `MinPQ` with the same idea of maintaining heap order
according to the insertion ID to implement the `Queue` ADT API.

### 2.4.27 Min() in MaxPQ

---

To implement the `min()` method, that should simply return the minimum element
in the collection, we simply maintain a pointer (variable), like `self._min`
within the class, that always stores the minimum element.

On every call to `insert()`, the inserted key is checked against the current
minimum value and updated if necessary. The value is always updated, if the PQ
was empty before.

The min-reference only needs to be updated on a call to `remove_max` if the last
element in the collection is being removed. This requires the `min` reference to
be updated to `None` again.

### 2.4.29 MinPQ/ MaxPQ

---

The idea here is to use 2 priority queues, an indexMinPQ and an indexMaxPQ.To
insert, we call insert on both PQs associating the item with the same index in
both. This isdone in logarithmic time.To find the max or min, we just call max()
on the maxPQ and min() on the minPQ,respectively. This is done in constant
time.To delete the maximum, we call delMax() on the maxPQ, which deletes the
maximum itemand returns its index. We then use this index to call delete(index)
on the minPQ. Both of theseoperations are done in logarithmic time. Similarly,
to delete the minimum we call delMin on theminPQ and use the index to delete
from the maxPQ.
