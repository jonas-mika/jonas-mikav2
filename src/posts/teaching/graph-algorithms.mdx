---
title: Graph Algorithms (DFS/ BFS)
description:
course: Algorithms & Data Structures
tags: []
published: 03-12-2022
lastEdited: 02-05-2023
---

Pairwise connections between items play a critical role in a vast array of
computational applications. A large number $n$ of such connections naturally
leads to the mathematical object of graphs. Graphs are the mathematical
representation of an infinite large number of pairwise connections and are being
studied in graph theory - a major branch of mathematics.

In computer sciences many popular and very important algorithms have evolved
that are based on graph theory and are used to compute the high variety of
problems associated to graphs, like ie. _Is an element in a graph? Are two
elements, who are in the same graph connected? If yes, what is the shortest path
between them?_ All these questions can be answered easily for small graphs - for
huge graphs, as ie. the network (_another term for graph)_ the internet, which
contains of millions and millions of nodes and edges, we need fast algorithms to
answer questions about our graphs.

Since in practical applications it is common that the volume of the data
involved for representing graphs is truly huge, efficient algorithms make the
difference between whether or not a solution is at all feasible.

Graphs are a particularly rich data structure that finds use in hundreds, if not
thousands, of real-world problems. Some of the most commonly referred to
examples of such real-world applications. Amongst those are **maps**, the
**internet** and any kind of **social network**.

## Graph Terminology

---

Mathematically, a graph comprises a non-empty set of vertices (also: nodes (from
knot)) and collection of edges (also: links), where each edge connects a pair of
vertices.

### Basic Terminology

---

**Vertex** (also node): An abstract object within a graph (depending on problem
modelled)

**Vertex Degree**: The degree of a vertex is the number of edges incident to it.
In directed graphs we differentiate between the in-degree and the out-degree,
which is the number of edges to and from the current vertex, respectively.

**Adjacent Vertex**: A vertex $u$ is called adjacent to $v$, if $v$ can be
reached from $u$ through a single edge.

**Edge**: A connection between two vertices

**Incident Edge**: An edge is called incident to/ on an vertex $u$ and another
vertex $v$, if it connects $u$ and $v$ directly.

**Walk**: Sequence of vertices connected by edges (arbitrary length and repeated
vertices and edges)

**Path**: Sequence of vertices connected by edges, with no repeated edges
(arbitrary length, repeated vertices, but no repeated edges)

**Simple Path**: Path with no repeated vertices (arbitrary length, no repeated
vertices or edges)

**Shortest Path**: The shortest path between two vertices is out of all possible
paths between these two vertices the shortest, ie. that minimises the path
length.

**Cycle**: A cycle is a path with at least one edge whose first and last
vertices are the same.

**Simple Cycle**: A simple cycle is a cycle with no repeated vertices (except
for the requisite repetition of the first and last vertices)

**Connected Vertices**: We say that a vertex $u$ is connected to $v$ if there
exists a path that contains both of them.

**Connected Graphs**: A graph is connected if there is a path from every vertex
to every other vertex in the graph. A graph that is not connected consists of a
set of connected components, which are maximal connected subgraphs.

## Types of Graphs

---

### Directed vs. Undirected Graphs

---

A directed graph edges are one-way, the pair of vertices that defines an edge is
an ordered pair that specifies a one-way adjacency. Many natural problems are
described by directed graphs, such as the internet (directed weblinks) or the
social network of Instagram (non-mutual following mechanism).

A undirected graph is the opposite of directed graphs, in a way that all edges
are bidirectional, meaning that each edge can be seen as a connection between
two nodes. An example of an undirected network might ie. be a street system
(without one-way streets).

### Weighted vs. Unweighted Graph

---

A weighted graph is a graph in which each edge is given a numerical weight.
Examples of weighted graphs can ie. be seen in a street network where the weight
corresponds to the length of the street that connects two vertices representing
intersections.

In contrast - an unweighted graph if a graph does not have any weights (or
equivalently: all weights are equal, ie. weight $n_i$ for $i \in V$ (=the set of
vertices).

### Simple vs. Multigraph

---

A **simple graph** is a graph that neither contain (self-)loops (=edges that
connect the same vertex) nor multiple edges (more than one edge connecting the
same pair of vertices)

The **multigraph** is the opposite of the simple graph. A multigraph is
permitted to have multiple/ parallel edges and (self-)loops.

*Note: The algorithms discussed within this course generally work for both
simple and multi-graphs. For the purpose of simplicity, we however consider
simple graphs.*V

### Connected vs. Unconnected Graph

---

A graph is connected if there is a path from every vertex to every other vertex
in the graph (If the graph would be a physical object, a connected graph would
stay in one piece, when picked up at an arbitrary knot (_vertex_))

Similarly, a graph is unconnected if there exists at least one pair of vertices
that can't be reached through a path. A graph that is not connected consists of
a set of connected components, which are maximal connected subgraphs.

### Cyclic vs. Acyclic Graph

---

A cyclic graph is a graph containing cycles.

An acyclic graph is a graph that does not contain cycles.

## Graph API

---

As with any rich object that we want to define in a datatype to employ efficient
algorithms onto one or many algorithmic problem, we first develop an API that
defines the fundamental graph operations that are necessary for us to answer
questions that arise for this data structure.

Surprisingly, this rather simple API allows us to solve most - even very
difficult - graph problems. It consists of two constructers - one that initiates
an empty graph with $V$ vertices and the other that initiates a graph from the
input stream (we don't know how this input stream must look for correct
read-in).

Then we have the simple operations `V()` and `E()` that just return the number
of vertices and edges, respectively. These are useful in later methods, as we
often need to iterate over either vertices or edges.

The `add_edge()` method allows us to further build up the graph. _Note that this
implementation does not allow us to add a single, non-connected vertex into the
graph._

The central method `adj()` is the core of the implementation and the method most
more complex algorithms depend on. For any given vertex it returns an `iterator`
object that holds all adjacent vertices (neighbours).

_Note, that this simple API for an undirected graph needs can be extended to
directed, weighted and other types of graphs through slight changes in the
underlying methods. The core idea, however, remains._

## Graph Data Structures

---

There are now several methods/ data structures/ graph representations we can
choose from that all hold all information about the graph, but differ in their
efficiency.

### Adjacency Matrix

---

A _adjacency matrix_ (_or in programming terms: two-dimensional array or list of
lists_) \*\*is a $V$-by-$V$ boolean array (only holding binary numbers, or the
boolean values `True` or `False`, where each entry at row $v$ and column $w$
indicates, whether there exists an edge (a connection) from vertex $v$ to vertex
$w$.

This data structure however is infeasible in reality for most graphs occurring
in practical applications. With a millions of vertices the space cost of a $V^2$
boolean array is prohibitive.

_Note furthermore that the adjacency matrix does have space for multigraphs,
since we cannot account for parallel edges in a boolean array._

### Array/ List of Edges

---

The next common approach are _edge lists/ arrays_. This is a simple
representation of a graph, in which we store many instances of `Edges` (a
datatype that consists of two integer instances) in a regular array.

Although this data structure is space efficient, it fails on the second count.
The key operations `adj()` takes linear time in the amount of edges $E$ for each
call. This is infeasible for graphs in reality.

### (Array of) Adjacency Lists

---

The standard way of representing graphs is therefore the so called _adjacency
list-data structure_ (at least for not dense graphs), where we keep track of all
vertices adjacent to each vertex on a `LinkedList` (`Bag`) that is associated
with each vertex by the index in the array.

## Searching Algorithms

---

Our first set of algorithms have the goal to search for all vertices that can be
reached given a source vertex that is provided as an input argument. Such search
algorithms do not only discover all reachable vertices from the source, but on
the go provide information about the connectivity of the given graph, ie. we can
instantly state whether or not the graph is connected (all vertices can be
reached from every vertex) if the number of explored nodes through the search is
equal to the total number of vertices in the graph. We can even further extend
the traversal of the graph to build so-called connected components.

**Using Searching for Connectivity**

To implement search algorithms we use the `Search` API that encodes the general
behaviour we expect for searching through a graph. We will consider one
fundamental algorithm that implement this behaviour. The algorithms are
fundamental to many more advanced algorithmic challenges evolving around graphs.

**Using Searching for Path Finding**

A somewhat related problem to the simple _searching_ query: For a given vertex
$s$, we want to query our object both for whether there exist a path to some
other vertex $u$ within the array from the source $s$. If so, we want to be able
to return the path as traced by out search algorithm that starts from $s$ and
ends at $u$.

_Note, that we cane extend this general idea to path-finding by narrowing our
path-finding algorithms to return paths having certain properties, such as
minimal lengths._

## Depth-First-Search (DFS)

---

Depth-first search is a fundamental recursive method to _search_ (also called
_traverse_) through a tree or graph data structure given a source vertex $s$.
The algorithm starts at the root node (selecting some arbitrary node as the root
node in the case of a graph) and explores as far as possible along each branch
before backtracking.

_A version of depth-first search was investigated in the 19th century by French
mathematician Charles Pierre Trémaux as a strategy for solving mazes. On closer
examination, graph traversal is a problem related closely for solving maxes._

The general idea of depth-first search is rather easy to grasp:

1. Invoke recursive depth-first search call on the source $s$, which means to
   mark the vertex to be visited (by setting the value at index `s` in `marked`
   to `True`)
2. Visit all the vertices that are _adjacent_ to it and have _not yet_ been
   _marked recursively,_ until reaching a vertex, for which all adjacent
   vertices have already been visited.
3. After reaching a base-case in a recursive call, we move one recursion level
   up, until we finally end our depth-first-search, when the top-level call to
   _dfs_ reaches its base case. This happens when all dfs calls to all adjacent
   vertices of the source $s$ are finished.

_Note, that the search behaviour as implemented in depth-first search follows a
path until the recursive depth is exhausted, and only then moves up one level of
recursion. The analogy of thinking of depth-first search - as the name suggest -
of first exploring a single path in all depth and only then moving to the next
path from the source is therefore quite helpful._

_DFS fundamentally is an algorithm that is constructed to work on directed
graphs, but also works on undirected graph, as these can be seen as a natural
extension of directed graphs, where each edge is bidirectional._

### Analysis

---

DFS marks all the vertices connected to the source $s$ in time proportional to
the sum of the degree of all visited nodes (worst case $V*\bar{D}$). The time
bound follows from the fact that we visit each marked vertex exactly once and
continue on each recursive call have to iterate over all adjacent vertices,
independently, whether we have visited our not visited them before.

## Breadth-First-Search (BFS)

---

Often we want to know what the shortest path to some vertex $w$ is given a
source vertex $s$. DFS fails in accomplishing this. While it gives one valid
path from $s$ to $w$, it might not be the shortest path. For this reason, we
often use another search approach, called _breadth-first search._ The algorithm
was designed in a way that it maximises the efficiency of finding shortest paths
in a graph.

_Breadth-first search_ (_BFS_) is an algorithm for traversing or searching tree
(just as _DFS_) or graph data structures. It starts at the tree root (or some
arbitrary node of a graph, referred to as the source $s$), and explores all of
the neighbouring vertices at the present depth prior to moving on to the nodes
at the next depth level.

_While DFS is analogous to one person exploring a maze, BFS mimics a group of
searchers exploring by fanning out in all directions. The result of breadth
first search thereby is a traversal of the graph into levels of depth (steps to
take from source vertex)._

### Procedure

---

The procedure of a breadth-first-search follows immediately from its
explanation. The implementation is based on a _queue_ for all vertices that have
been marked, but whose adjacency lists have not yet been checked. We put the
source vertex onto the queue and then perform the following steps until the
queue is empty:

1. Remove the next vertex $v$ from the queue
2. Put onto the queue all unmarked vertices that are adjacent to v and mark them

_Note that in contrast to DFS, BFS is not recursive, but uses an explicit data
structure, namely the queue._

_Just as DFS, BFS fundamentally is an algorithm that works on directed graphs,
but also works on undirected graph, as these can be seen as a natural extension
of directed graphs, where each edge is bidirectional._

## Exercise Solutions

---

### 4.1.1 Maximum/ Minimum Number of Edges in a Graph

---

We know that in a undirected, simple graph with $V$ vertices, each vertex can
connect to $V-1$ other vertices. This gives $V\cdot(V-1)$. We divide by $2$,
since in an undirected graph the edge $(u, v)=(v,u)$. At last, we add $V$
possible self-loops, since the exercise does not state that these are
disallowed. This leads to the final maximum number of edges:

$$
\frac{V(V-1)}{2}+V
$$

For the same type of graph, the minimum number of edges, following the
requirement that no vertex is isolated (but the graph does not necessarily have
to be fully connected) is the ceiling of half the number of the total vertex
number. The reasoning is that each vertex must at least have a single connection
to not be isolated. With a single edge we can connect two vertices. Thus, we
need $V/2$ vertices to create $V/2$ pairs of vertices. The ceiling occurs if the
number of vertices is odd, which will require us to use one extra edge.

$$
\ceil{V/2}
$$

### 4.2.1 Maximum/ Number of Edges in a DiGraph

---

Following the reasoning from above, each vertex can connect to all other
vertices and to itself. Thus each of the $V$ vertices has at most $V$ vertices
to connect to, leading to the maximum number of vertices to be

$$
V^2
$$

The minimum number of vertices in a directed graph, without having any vertices
isolated remains to be

$$
\ceil{V/2}
$$

### 4.1.28 Isomorphic Graphs

---

Two graphs are isomorphic if a relabelling of the vertices would lead to the
exact same graphs. It follows, that graphs are non-isomorphic if their
architecture is different. We are therefore searching for different topological
arrangements of the vertices and

1. There are 2 non-isomorphic graphs with two vertices.

2. There are 4 non-isomorphic graph with three vertices.

3. There are 11 non-isomorphic graphs with four vertices.

### 4.2.9 Isomorphic Digraphs

---

1. There are 2 non-isomorphic directed graphs with two vertices.

2. There are 6 non-isomorphic directed graph with three vertices.

3. There are 28 non-isomorphic directed graphs with four vertices.

### 4.1.12 BFS Tree

---

The BFS tree is a tree rooted at the source $u$ of the BFS traversals. The depth
of any node $v$ in the tree is equivalent to the shortest path (distance),
$dist(u, v)$. For two nodes $u$ and $v$ that are both not the root, we cannot
directly induce a precise distance between the two nodes. However given their
level in the BFS tree, denoted as $L_u$ and $L_v$, we can give a lower and upper
bound for the distance between the two nodes:

$$
|L_u - L_v| \le dist(u, v) \le L_u + L_v
$$

The upper bound follows, since we are guaranteed that there exists a path from
the node $u$ to the root, and then from the root to node $v$ or reversely. The
distance of this path is precisely the sum of the two dephts of $u$ and $v$ in
the tree. The lower bound follows from the fact, that neighboring nodes can have
a difference of at most one. The lower bound then follows inductively.

### 4.1.16 Graph Terminology

---

**Eccentricity (longest shortest path)**

Run a BFS from the source node and while traversing keep track of the number of
iterations the traversal took. After the BFS traversal finishes, the reference
to the number of iterations is equivalent to the eccentricity of the vertex as
it stores the longest shortest path from the source node.

**Diameter (maximum eccentricity)**

Find the eccentricity of all nodes and then take the maximum of the list.

**Radius (smallest eccentricity)**

Find the eccentricity of all nodes and then take the minimum of the list.

**Center (vertex whose eccentricity is the radius of the graph)**

Compute the radius, and return all nodes whose eccentricity is equivalent to the
radius.

### 4.1.21 Bipartite Coloring

---

The bipartite coloring class as per S&W 547 uses a classical DFS traversal
through the graph. On top of that, it maintains an array `color`, which stores
the coloring of each of the nodes in the graph and a boolean variable
`isTwoColorable` that is initially set to `True`.

We iterate through the graph from a start node and use the regular recursive DFS
calls. Before the recursive call we now also set the color of the next node on
the recursive stack to be to opposite of the current node. If we encounter a
neighboring node that has already been colored, then we check if the colors are
opposites (as necessary for a bipartite coloring). If they are the same, we set
the boolean `isTwoColorable` to False and stop the traversal.

Similarly, we could use the same extension of the classical graph traversal, but
use BFS as our mode of traversing through the graph. The ordering of visiting
nodes naturally changes, but the coloring is the same (not taking into
consideration that one implementation may start out with different colors for
the source node).

### 4.1.32 Counting Parallel Edges

---

We assume the graph to be given as an adjacency list. For each vertex, consider
the neighbors, count how many single-edge-connections there are to each
neighbor. If there are at least two, all edges to that neighbor are parallel
edges and we add this to the total number of edges encountered. We divide the
final count by two, to account for us counting parallel edges between nodes $u$
and $v$ twice, once while visiting $u$ and once while visiting$v$. Instead of
initialising a new array, we reuse the array by resetting it instead of creating
a new one. The algorithm runs in time $O(V+E)$.

### 4.1.36 Bridge Detection

---

Start by checking that the graph is connected, by running either DFS or BFS and
ensuring that every vertex is reachable. Then notice that the running time
requirement is O(E ·(V + E)), suggesting we can run either BFS or DFS for each
edge in the graph. For edge e to be a bridge, its removal from the graph must
make one or more vertices unreachable. So for each edge, remove the edge from
the graph (doable in constant time in adjacency list format, but even linear
cost would not be problematic) and run either DFS or BFS. If the new graph
without edge e is still connected, e is not a bridge and we can add e back to
the graph and check the next edge. If we get through all edges without finding a
bridge, the graph is edge connected.
