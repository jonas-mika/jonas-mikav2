---
title: The Gradient
description:
course: Linear Algebra & Optimisation
tags: []
published: 2022-11-28
lastEdited: 2022-11-28
---

Last week we first introduced _multivariate functions_ of the form $f:
\R^m\rightarrow\R$:

> A function $f$ in $m$ input variables $x_1, ...,x_m$ is a mapping that assigns to each ordered pair of $m$ real numbers $(x_1, ...,x_m)$ a unique
> real number denoted as $f(x_1,...,x_m)$.

Further, recall that if we want to speak about the (instantaneous) rate-of-growth of $f$, it is no longer sufficient to represent this through a
single scalar as we could in the univariate case. Rather, we need to talk about the rate-of-change of the output in relation to every possible input
$x_1, ..., x_m$, which is expressed in the notion of _partial derivatives_:

> A partial derivative $f_{x_1}=\frac{\delta f}{\delta x_1}: \R^m \rightarrow \R$ is a function describing the rate-of-change of the output
> $f(x_1, ..., x_m)$ for (minimal) changes in $x_1$.

However, the partial derivatives on their own are often little informative for real-world questions, as they only give information about the
rate-of-change along the input dimensions. If we want to investigate rate-of-change in any direction (e.g. one especially interesting one is the
direction of maximum ascend), then we need to alter our multivariate calculus toolset. Today we are going to develop an understanding for
**directional derivatives**, and how one special case of such, the **gradient vector**, occurs naturally in many applications for optimisation.

## Directional Derivatives

---

I will try to motivate the notion of directional derivatives with a concrete example, which we will use throughout this chapter.

> Imagine we are on a hiking trip and we happen to know the (approximate) functional form of the mountain that we are climbing. The altitude of the
> mountain $z$ over some area described though a coordinate set $(x,y)$ is modelled in the surface $f:\R^2\rightarrow\R$.

The below visualisation visualises the level curves at $k=1200$, ..., $k=400$ meters of altitude with a constant step size of 200. We see, that the
mountain seems to have its summit in the origin and that we currently on route towards the mountain standing in some position $(x_0, y_0)$ (`ME` in
the plot).

![partial-derivatives](/teaching/lao/partial-derivatives.png)

Now, at this particular point in time, I might not be interested in the ascend in the north-south direction (partial derivative w.r.t $y$), nor in the
east-west direction (partial derivative w.r.t $x$), because the only hiking trail goes in the south-west direction (towards the summit). So far, we
have not developed the tools to talk about the rate-of-change (here: _ascend_) in _any_ direction. Let's try to formulate this problem mathematically.
If we can decribe the direction of interested through a **unit vector** $\bold{u}=(a,b)$, then the following limit expression tells us the directional
derivative $D_u$ along the surface $f$ in a specific point $(x_0, y_0)$:

$$
D_uf(x_0,y_0)=lim_{h\rightarrow 0}\frac{f(x_0+ha, y_0+hb)-f(x_0, y_0)}{h}
$$

_Notice, that here we are measuring the difference in the output of $f$, if we move an infinitely small step in the direction of $(a,b)$_

Further notice that if $(a,b)=(1,0)=\bold{i}$, then this limit is the same as the partial derivative $f_x$, and so goes for $f_y$ if we let
$(a,b)=(0,1)=\bold{j}$. In that sense, the partial derivatives are just special directional derivatives. We can use this property, to not having to
evaluate the limit expression manually anytime we are interested in the rate-of-change in arbitrary directions. Instead, we can simply scale the
output of the partial derivatives (special directional derivatives) with the respective coordinates of the unit vector.

$$
D_uf(x,y)=f_x(x,y)a+f_y(x,y)b
$$

Having our linear algebra classes not too far back, this expression (a sum over coordinate-wise products) should look oddly familiar to you. If we
collect the partial derivatives into a vector, then we can express this expression as the dot product of the unit vector $\bold{u}$ and the vector of
partial derivatives.

$$
\begin{align*}
D_uf(x,y)&=(f_x(x,y), f_y(x,y))\cdot (a,b)\\
&=(f_x(x,y), f_y(x,y))\cdot \bold{u}
\end{align*}
$$

Et voila, we have discovered the **gradient vector**, which is a name for the vector collecting all partial derivatives.

Lastly, I want to make note of the fcat that we can describe the rate-of-growth (scalar) of directional derivatives through the length (magnitude) of
the directional vector $D_uf$.

$$
|D_u f(x,y)|
$$

## The Gradient Vector

---

Let's summarise, what we have discovered about the gradient vector. Simply put, the gradient vector $\nabla f$ is simply the vector collecting all the
partial derivatives of a multivariate function $f$.

On a more formal level, we should notice that the _gradient_ (vector output when evaluating the partial derivatives at specific input) is just the
output of a more general _gradient vector function_ $\nabla f(x,y)$. Since this function collects $m$ multivariate functions
$f_{x_i}: \R^m\rightarrow\R$ is is actually a vector function (multiple outputs) with multiple inputs and has thus the functional form
$\nabla f: \R^m\rightarrow\R^m$

$$
\begin{align*}
   \nabla f(x_1,..., x_m)=\begin{bmatrix}f'_{x_1}(x_1,...,x_m) \\
   \vdots \\
   f'_{x_m}(x_1, ..., x_m)\end{bmatrix}
\end{align*}
$$

Now, apart from finding application when computing arbitrary _directional derivatives_ as we have seen, the gradient vector has some interesting
natural properties:

1. **$\nabla f(x,y)$ points in the direction of fastest growth**

   By theorem, if we consider all possible directions $\bold{u}$ and evaluate their directional derivatives $D_uf$, the direction that maximises the
   rate-of-growth $|D_uf|$ has the same direction has the gradient vector. This means, that the gradient always points in the direction of steepest
   ascend (and similar its opposite in the direction of steepest descend).

2. **$\nabla f(x,y)$ is perpendicular to the level curves of $f$**

   This means that the dot product of the gradient at a specic point and the tangent line to the level curve is going to be $0$.

What does this mean for our running example? Well, I can compute the gradient vector at my current position (`Me` in the figure) by evaluating the
gradient function at the that position $(x_0, y_0)$ through $\nabla f(x_0, y_0)$. This vector is (a) perpendicular the the level curve at $k=400$ (the
height of `Me`) and points right towards the summit. Its magnitude (a scalar) tells me the rate-of-growth in that direction, which is the direction
that is steepest to hike towards.

![gradient-vector](/teaching/lao/gradient-vector.png)

## Optimisation

---

Now, how can we use all of this for finding stationary points (_or: critical points_) of multivariate functions? In our example, we would like to find
out at which coordinates $(x,y)$ the mountain is maximally high. Again, the analogy to the univariate case is useful to motivate what we are doing:

> A univariate function $f:\R\rightarrow\R$ has stationary points, where $f'(x)=0$

In words, we are searching for the roots of the first derivative, which is equivalent to searching for inputs $x$ to $f$, at which the rate-of-change
is zero. Such points only occur at _minima_, _maxima_ and at _saddle points_.

The same is true in the multivariate case. For a function in two inputs $f(x,y)$, there exist stationary points, where both partial derivatives are 0.
Using our knowledge of gradients, we can write this condition in a single vector equation.

$$
\nabla f(x,y) = 0
$$

This is a system of (potentially non-linear) equations in two equations and two unknowns, so you can alternatively write it out as

$$
\begin{align*}
f_x(x,y) = 0\\
f_y(x,y) = 0
\end{align*}
$$

Now, assuming there exists a solutions to this equation set, we have found a set that satisfies the condition $\{(a,b)|\nabla f(a,b)=0\}$. Like in the
univaraite case, this does not mean, that each of these points is a local minimum or maximum, as saddle points can also occur in the multivariate
case. For this reason, we need to do the **second derivative test**, which defines a set of rules to determine what type of critical points you have
found in the case of functions in two inputs.

For this, collect the partial derivatives $f_{xx}$, $f_{xy}=f_{yx}$ and $f_{yy}$ into a matrix

$$
\begin{bmatrix}
f_{xx} & f_{xy} \\
f_{yx} & f_{yy}
\end{bmatrix}
$$

Now, according to the closed formula for $2\times 2$ matrices, the determinant is

$$
D=f_{xx}(a,b)f_{yy}-[f_{xy}(a,b)]^2
$$

And you can use follow the following rules for determining the type of critical point $f(a,b)$ is

1. If $D\gt 0$ and $f_xx(a,b)\gt 0$, then $f(a,b)$ is a **local minimum**

2. If $D\gt 0$ and $f_xx(a,b)\lt 0$, then $f(a,b)$ is a **local maximum**

3. If $D\lt 0$, then $f(a,b)$ is a **saddle point**

## Optimisation under constraints: Langrange Multipliers

---

The above equips us with all the tools needed to optimise any kind of function $f(x_1, ..., x_m)$, i.e. finding its minimum and maximum values.
However, in many applications there are some natural constraints on the set of inputs, that could mean for example that a global maximum of $f$ is not
valid, because the set of inputs that produce it are not valid. To deal with optimisation problems of such kind (which you will see appear a lot in
the context of machine learning), we use the technique of **Lagrange multipliers**.

To have a well-defined problem, let's go back to our hiking example. Our function $z=f(x,y)$ still maps the altitude $z$ for all coordinate pairs
$(x,y)$ and the mountain has its summit in the origin. Now, imagine that the reasons of why my current position is somewhere in the top-right is,
because I am on the "red hiking trail", which in the below figure is illustrated projected onto the xy-plane as the red line. If I can only move on
this path, then a natural question to ask would be, what the _maximum_ altitude I can reach on this hiking trail would be.

![lagrange-multiplier](/teaching/lao/lagrange.png)

Mathematically, this is precisely an optimisation under constraints. Here, we want to optimise $f(x,y)$ under the constraint of only considering pairs
of coordinates, which lie on the red hiking trail, which we may describe through $g(x,y)=k$.

$$
\begin{align*}
   \text{Optimise } f(x,y)\\
   \text{subject to } g(x,y)=k
\end{align*}
$$

Now, studying the plot (and knowing about the shape of our mountain), it seems clear that the maximum height I can reach along the red hiking trail is
at the red point. Now, how might we describe this mathematically. A distinguishing feature of this point seems to be that it is the only point where
the level curves of $f$ and $g$ are touching (and not intersecting). As we know that gradient vectors are always perpendicular to level surfaces, we
can conclude, that the two gradient vectors in the red points (critical point under constraint) must be parallel. Therefore the two gradients must be
scalar multiples of each other

$$
\nabla f(x,y)=\lambda \nabla g(x,y)
$$

We denote the scalar through $\lambda$ and usually call it a **lagrange multiplier**. Let's conclude: We have seen that in order to optimise a
function $f$ under a constraining function $g$ boils down to finding sets of points, for which their gradients are paralell to each other. However, we
still only want to consider points that are valid given our constraint, so the full **method of lagrange multipliers** solves the following systems of
equations:

$$
\begin{align*}
\nabla f(x,y)&=\lambda \nabla g(x,y)\\
g(x,y)&=k\\
\end{align*}
$$

Often, these are combined into a single equation, called the **Lagrangian function**, which is usually simpler to solve as it is a single expression

$$
L(x,y,\lambda)=f(x,y)-\lambda (g(x,y)-k)
$$
